# -*- coding: utf-8 -*-
"""IT352_Project_Book2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19gXDdgVu1xd-QAa_rYByV7SAqDjbvfBG
"""

import numpy as np
import cv2
import math
from google.colab.patches import cv2_imshow
from skimage.metrics import structural_similarity as ssim

path = "/leaf3.jpg"
img = cv2.imread("/content/drive/MyDrive/IT352_Project/Submission 2/images" + path)

height, width, channels = img.shape

median_filtered_image = cv2.medianBlur(img, 5)
cv2_imshow(median_filtered_image)

hsv = cv2.cvtColor(median_filtered_image, cv2.COLOR_BGR2HSV)
cv2_imshow(hsv)

lower_hue = 0  # Start from the lowest possible hue (0)
upper_hue = 180  # End at the highest possible hue (180)
lower_saturation = 100  # Minimum saturation (filtering out grayish or very dull colors)
upper_saturation = 255  # Maximum saturation (capturing all colorful leaves)
lower_value = 50  # Minimum value to avoid dark and black regions
upper_value = 255  # Maximum value to include all brightness levels

# Create a mask using the defined HSV range
lower_bound = np.array([lower_hue, lower_saturation, lower_value])
upper_bound = np.array([upper_hue, upper_saturation, upper_value])

mask = cv2.inRange(hsv, lower_bound, upper_bound)

kernel = np.ones((5, 5), np.uint8)  # 5x5 kernel for dilation
# dilated_mask = cv2.dilate(mask, kernel, iterations=1)
opened_mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
# closed_mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)
# Show the result (binary image)
# cv2_imshow(dilated_mask)
cv2_imshow(opened_mask)

# Save the binary mask image
# cv2.imwrite('binary_leaf_image.jpg', dilated_mask)

edges = cv2.Canny(opened_mask, 50, 150)
cv2_imshow(edges)

contours, _ = cv2.findContours(edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)

def calculate_centroid(contour):
    M = cv2.moments(contour)
    if M["m00"] != 0:
        cx = int(M["m10"] / M["m00"])
        cy = int(M["m01"] / M["m00"])
        return (cx, cy)
    else:
        return (0, 0)

print(img.shape)
total_image_area = img.shape[0] * img.shape[1]
dynamic_min_area = 0.000008 * total_image_area  # 0.1% of the image area
filtered_contours = [cnt for cnt in contours if cv2.contourArea(cnt) > dynamic_min_area]
# size_contours = [cnt for cnt in contours if cv2.contourArea(cnt) > dynamic_min_area]

# # Set a threshold distance between contours (in pixels)
# distance_threshold = 100  # Change based on your needs
# centroids = [calculate_centroid(cnt) for cnt in size_contours]

# distances = []
# for i in range(len(centroids)):
#     for j in range(i+1, len(centroids)):
#         dist = math.sqrt((centroids[i][0] - centroids[j][0]) ** 2 + (centroids[i][1] - centroids[j][1]) ** 2)
#         distances.append(dist)

# # DYNAMIC: Calculate the average distance between contours and set the min_distance dynamically
# if distances:
#     dynamic_min_distance = np.mean(distances) * 0.5  # Set threshold as half of the average distance
# else:
#     dynamic_min_distance = 100  # Default if no contours are found

# # Filter out contours that are too far away from the main group
# filtered_contours = []
# for i, cnt1 in enumerate(size_contours):
#     keep = True
#     for j, cnt2 in enumerate(size_contours):
#         if i != j:
#             centroid1 = centroids[i]
#             centroid2 = centroids[j]
#             distance = math.sqrt((centroid1[0] - centroid2[0]) ** 2 + (centroid1[1] - centroid2[1]) ** 2)
#             if distance > dynamic_min_distance:
#                 continue
#             keep = False
#             break
#     if keep:
#         filtered_contours.append(cnt1)

# filtered_contours = [cnt for cnt in contours]


# min_contour_area = 100
# filtered_contours = [cnt for cnt in contours if cv2.contourArea(cnt) > min_contour_area]

# Find the bounding box that encompasses all filtered contours
if filtered_contours:
    # Concatenate all contours into a single array
    combined_contours = np.concatenate(filtered_contours)

    # Find the bounding rectangle for the combined contours
    x, y, w, h = cv2.boundingRect(combined_contours)

    # Draw the bounding rectangle on the original image
    cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)

    # Display the image with the merged ROI
    cv2_imshow(img)

    # Extract the ROI
    roi = img[y:y+h, x:x+w]
    print(img.shape)
    print(roi.shape)
    cv2_imshow(roi)
else:
    print("No significant contours found.")

resized = cv2.resize(roi, (width, height) , 1, 1, cv2.INTER_LINEAR)
cv2_imshow(resized)
print(resized.shape)

img_np = np.squeeze(img)
re_np = np.squeeze(resized)
# score, diff = ssim(img_np, re_np, full=False, win_size=1, use_sample_covariance=False)
score = ssim(img_np, re_np, full=False, win_size=1, use_sample_covariance=False)
# print("Similarity Score: {:.3f}%".format(score * 100))
print(score)
cv2.imwrite("/content/drive/MyDrive/IT352_Project/Submission 2/output"+path, resized)